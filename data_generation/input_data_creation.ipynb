{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Data Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script performs the cohort selection and data extraction for the convolutional neural network. It takes all hospital admissions for patients with heart failure and retreives the departments, as well as the laboratory values and demographic information. This project was conducted with MIMIC-IV 0.4, which is important, as version 1.0 was released just recently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from psycopg2 import connect\n",
    "import pandas as pd\n",
    "import pm4py\n",
    "import numpy as np\n",
    "import pandasql as ps\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "con = connect(dbname=\"postgres\", host=\"127.0.0.1\", user=\"postgres\", password=\"1234\")\n",
    "con.set_client_encoding('utf8')\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adms(df, hadm_ids):\n",
    "    cursor.execute('SELECT * FROM mimic_core.admissions where hadm_id = any(%s)', [hadm_ids])\n",
    "    adms = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    adms = pd.DataFrame(adms, columns=cols)\n",
    "    b_adms = adms.loc[adms[\"hadm_id\"].isin(hadm_ids)]\n",
    "    b_adms.drop(\"subject_id\", axis=1, inplace=True)\n",
    "    b_adms = df.merge(b_adms, on=\"hadm_id\", how=\"inner\")\n",
    "    b_adms = b_adms.drop_duplicates(\"hadm_id\")\n",
    "    return b_adms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires get_adms for admission/discharge location!\n",
    "def get_transfers(df, hadm_ids):\n",
    "    cursor.execute('SELECT * FROM mimic_core.transfers where hadm_id = any(%s)', [hadms])\n",
    "    transfers = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    transfers = pd.DataFrame(transfers, columns=cols)\n",
    "    b_trans = transfers.loc[transfers[\"hadm_id\"].isin(hadm_ids)]\n",
    "    b_trans = b_trans.sort_values([\"subject_id\", \"hadm_id\",\"intime\"])\n",
    "    b_trans.loc[(b_trans[\"careunit\"].isna()) & (b_trans[\"eventtype\"] == \"transfer\"), \"careunit\"] = \"Unknown\"\n",
    "    b_trans.loc[(b_trans[\"careunit\"].isna()) & (b_trans[\"eventtype\"] == \"admit\"), \"careunit\"] = \"Admit\"\n",
    "    b_trans.loc[(b_trans[\"careunit\"].isna()) & (b_trans[\"eventtype\"] == \"discharge\"), \"careunit\"] = \"Discharge\"\n",
    "        #Set first careunit to admission location\n",
    "    b_trans = b_trans.drop(\"subject_id\", axis=1)\n",
    "    b_trans = b_trans.merge(df, on=\"hadm_id\", how=\"inner\")\n",
    "    b_trans.loc[b_trans[\"careunit\"] == \"Discharge\", \"careunit\"] = b_trans[\"discharge_location\"]\n",
    "    b_trans = b_trans.sort_values([\"subject_id\", \"hadm_id\",\"intime\"])\n",
    "    first_careunit = b_trans.loc[~b_trans.duplicated(\"hadm_id\", keep=\"first\")]\n",
    "    admission_location = []\n",
    "    for index, row in first_careunit.iterrows():\n",
    "        add_row = row\n",
    "        add_row[\"careunit\"] = row[\"admission_location\"]\n",
    "        add_row[\"outtime\"] = row[\"intime\"] \n",
    "        add_row[\"transfer_id\"] = np.nan\n",
    "        add_row[\"intime\"] = add_row[\"outtime\"] - pd.Timedelta(seconds=1)\n",
    "        admission_location.append(add_row)\n",
    "    admission_location = pd.DataFrame(admission_location)\n",
    "    b_trans_admission_location = pd.concat([first_careunit, admission_location])\n",
    "    b_trans = b_trans.loc[b_trans.duplicated(\"hadm_id\", keep=\"first\")]\n",
    "    b_trans = pd.concat([b_trans, b_trans_admission_location])\n",
    "    b_trans = b_trans.sort_values([\"subject_id\",\"hadm_id\", \"intime\"])\n",
    "    return b_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requires get_transfers\n",
    "def get_patients(df):\n",
    "    cursor.execute(\"SELECT * FROM mimic_core.patients\")\n",
    "    patients = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    patients = pd.DataFrame(patients, columns=cols)\n",
    "    b_trans_patient = df.merge(patients, on=\"subject_id\", how=\"inner\")\n",
    "    b_trans_patient[\"transfer_year\"] = b_trans_patient.apply(lambda x: x[\"intime\"].year , axis=1)\n",
    "    b_trans_patient[\"transfer_age\"] = (b_trans_patient[\"transfer_year\"] - b_trans_patient[\"anchor_year\"]) + b_trans_patient[\"anchor_age\"]\n",
    "    b_trans_patient[\"anchor_real_year\"] = b_trans_patient[\"anchor_year_group\"].str.slice(0,4)\n",
    "    b_trans_patient[\"anchor_real_year\"] = pd.to_numeric(b_trans_patient[\"anchor_real_year\"])\n",
    "    b_trans_patient[\"anchor_real_year\"] = b_trans_patient[\"anchor_real_year\"] + 1\n",
    "    b_trans_patient[\"transfer_real_year\"] = b_trans_patient[\"anchor_real_year\"] + b_trans_patient[\"transfer_year\"] - b_trans_patient[\"anchor_year\"]\n",
    "    b_trans_patient.loc[b_trans_patient[\"transfer_real_year\"] == 2021, \"transfer_real_year\"] = 2020\n",
    "    b_trans_patient = b_trans_patient.sort_values([\"hadm_id\", \"intime\"])\n",
    "    \n",
    "    #set patient age for hospital admission according to first transfer in admission\n",
    "    b_trans_patient.loc[~b_trans_patient.duplicated(\"hadm_id\", keep=\"first\"), \"admission_age\"] = b_trans_patient[\"transfer_age\"]\n",
    "    b_trans_patient.loc[b_trans_patient[\"admission_age\"] <= 18, \"admission_age_group\"] = \"0-18\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 25) & (b_trans_patient[\"admission_age\"] > 18), \"admission_age_group\"] = \"19-25\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 35) & (b_trans_patient[\"admission_age\"] > 25), \"admission_age_group\"] = \"26-35\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 45) & (b_trans_patient[\"admission_age\"] > 35), \"admission_age_group\"] = \"36-45\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 55) & (b_trans_patient[\"admission_age\"] > 45), \"admission_age_group\"] = \"46-55\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 65) & (b_trans_patient[\"admission_age\"] > 55), \"admission_age_group\"] = \"56-65\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 75) & (b_trans_patient[\"admission_age\"] > 65), \"admission_age_group\"] = \"66-75\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] <= 85) & (b_trans_patient[\"admission_age\"] > 75), \"admission_age_group\"] = \"76-85\"\n",
    "    b_trans_patient.loc[(b_trans_patient[\"admission_age\"] > 85), \"admission_age_group\"] = \"85+\"\n",
    "   ###create patient groups!!#####\n",
    "    return b_trans_patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_services(df, hadm_ids):\n",
    "    cursor.execute('SELECT * from mimic_hosp.services where hadm_id = any(%s)', [hadm_ids])\n",
    "    services = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    services = pd.DataFrame(services, columns=cols)\n",
    "    b_services = services.loc[services[\"hadm_id\"].isin(hadms)]\n",
    "    b_services = b_services.drop(\"subject_id\", axis=1)\n",
    "    b_services = b_services[[\"hadm_id\", \"transfertime\", \"curr_service\"]]\n",
    "    \n",
    "    sqlcode = '''\n",
    "    select *\n",
    "    from df\n",
    "    left join b_services on df.hadm_id=b_services.hadm_id\n",
    "    where b_services.transfertime >= df.intime and  b_services.transfertime < df.outtime \n",
    "\n",
    "    '''\n",
    "\n",
    "    newdf = ps.sqldf(sqlcode,locals())\n",
    "    newdf = newdf.loc[:,~newdf.columns.duplicated()]\n",
    "    newdf = newdf.drop_duplicates([\"hadm_id\", \"careunit\", \"intime\", \"outtime\", \"curr_service\"])\n",
    "    df = df.reset_index()\n",
    "    df.drop(\"index\", axis=1, inplace=True)\n",
    "    for index, row in newdf.iterrows():\n",
    "        df.loc[(df[\"hadm_id\"] == row[\"hadm_id\"]) & (df[\"intime\"] == row[\"intime\"]) & (df[\"outtime\"] == row[\"outtime\"]), \"service\"] = row[\"curr_service\"]\n",
    "        df.loc[(df[\"hadm_id\"] == row[\"hadm_id\"]) & (df[\"intime\"] == row[\"intime\"]) & (df[\"outtime\"] == row[\"outtime\"]), \"service_time\"] = row[\"transfertime\"]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_procedures(df, hadm_ids):\n",
    "    cursor.execute('SELECT * from mimic_hosp.procedures_icd where hadm_id = any(%s)', [hadm_ids])\n",
    "    proc = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    proc = pd.DataFrame(proc, columns=cols)\n",
    "    cursor.execute(\"SELECT * from mimic_hosp.d_icd_procedures\")\n",
    "    proc_d = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    proc_d = pd.DataFrame(proc_d, columns=cols)\n",
    "    bp_proc = proc.loc[proc[\"hadm_id\"].isin(hadm_ids)]\n",
    "    bp_proc = bp_proc.merge(proc_d, on=[\"icd_code\", \"icd_version\"], how=\"inner\")\n",
    "    d = bp_proc.groupby(['subject_id','hadm_id']).agg({\"icd_code\":lambda x: list(x), \"seq_num\":lambda x: list(x), \"icd_version\":lambda x: list(x), \"long_title\":lambda x: list(x)})\n",
    "    d = d.rename(columns={\"icd_code\":\"proc_icd_code\", \"seq_num\":\"proc_seq_num\", \"icd_version\":\"proc_icd_version\", \"long_title\":\"proc_long_title\"})\n",
    "    d = d.reset_index()\n",
    "    d = d.drop(\"subject_id\", axis=1)\n",
    "    df = df.merge(d, on=\"hadm_id\", how=\"left\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meds(hadm_ids):\n",
    "    cursor.execute('select * from mimic_hosp.pharmacy where hadm_id = any(%s)', [hadm_ids])\n",
    "    pharmacy = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    pharmacy = pd.DataFrame(pharmacy, columns=cols)\n",
    "    pharmacy = pharmacy.sort_values([\"subject_id\", \"hadm_id\", \"starttime\"])\n",
    "    pharmacy = pharmacy.loc[~pharmacy[\"medication\"].isna()]\n",
    "    return pharmacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_med_count(df, transfers, hadm_ids):\n",
    "    cursor.execute('select * from mimic_hosp.pharmacy where hadm_id = any(%s)', [hadm_ids])\n",
    "    pharmacy = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    pharmacy = pd.DataFrame(pharmacy, columns=cols)\n",
    "    pharmacy = pharmacy.sort_values([\"subject_id\", \"hadm_id\", \"starttime\"])\n",
    "    pharmacy = pharmacy.loc[~pharmacy[\"medication\"].isna()]\n",
    "    \n",
    "    sqlcode = '''\n",
    "    select *\n",
    "    from pharmacy\n",
    "    left join transfers on pharmacy.hadm_id=transfers.hadm_id\n",
    "    where pharmacy.starttime >= transfers.intime and pharmacy.starttime <= transfers.outtime\n",
    "    '''\n",
    "\n",
    "    newdf = ps.sqldf(sqlcode,locals())\n",
    "    newdf = newdf.loc[:,~newdf.columns.duplicated()]\n",
    "    med_count = newdf.groupby([\"hadm_id\",\"transfer_id\"]).count()\n",
    "    med_count = med_count.reset_index()\n",
    "    med_count = med_count.drop(['pharmacy_id', 'poe_id',\n",
    "       'starttime', 'stoptime', 'medication', 'proc_type', 'status',\n",
    "       'entertime', 'verifiedtime', 'route', 'frequency', 'disp_sched',\n",
    "       'infusion_type', 'sliding_scale', 'lockout_interval', 'basal_rate',\n",
    "       'one_hr_max', 'doses_per_24_hrs', 'duration', 'duration_interval',\n",
    "       'expiration_value', 'expiration_unit', 'expirationdate', 'dispensation',\n",
    "       'fill_quantity', 'eventtype', 'intime', 'outtime',\n",
    "       'drg_type', 'drg_code', 'description', 'drg_severity', 'drg_mortality',\n",
    "       'count_icd', '1_icd', '1_desc_icd', '2_icd', '2_desc_icd', '3_icd',\n",
    "       '3_desc_icd', 'admittime', 'dischtime', 'deathtime', 'admission_type',\n",
    "       'admission_location', 'discharge_location', 'insurance', 'language',\n",
    "       'marital_status', 'ethnicity', 'edregtime', 'edouttime',\n",
    "       'hospital_expire_flag', 'careunit'], axis=1)\n",
    "    med_count = med_count.rename(columns={\"subject_id\":\"med_count\"})\n",
    "    df = df.merge(med_count, on=[\"hadm_id\", \"transfer_id\"], how=\"left\")\n",
    "    df = df.drop_duplicates([\"hadm_id\", \"transfer_id\", \"med_count\"])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diagnoses(df, hadm_ids, n):\n",
    "    cursor.execute('SELECT * FROM mimic_hosp.diagnoses_icd where hadm_id = any(%s)', [hadm_ids])\n",
    "    icds = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    icds = pd.DataFrame(icds, columns=cols)\n",
    "    \n",
    "    cursor.execute(\"SELECT * FROM mimic_hosp.d_icd_diagnoses\")\n",
    "    desc_icd = cursor.fetchall()\n",
    "    cols = list(map(lambda x: x[0], cursor.description))\n",
    "    desc_icd = pd.DataFrame(desc_icd, columns=cols)\n",
    "    desc_icd = desc_icd[[\"icd_code\", \"long_title\"]]\n",
    "    \n",
    "    b_icds = icds.loc[icds[\"hadm_id\"].isin(hadm_ids)]\n",
    "    count_icd = b_icds.groupby(\"hadm_id\").count()\n",
    "    count_icd = count_icd.reset_index()\n",
    "    count_icd = count_icd[[\"hadm_id\", \"seq_num\"]]\n",
    "    df = df.merge(count_icd, on=\"hadm_id\", how=\"inner\").rename(columns={\"seq_num\":\"count_icd\"})\n",
    "    for i in range (1, n+1):\n",
    "        to_join = b_icds.loc[b_icds[\"seq_num\"] == i][[\"hadm_id\", \"icd_code\"]]\n",
    "        df = df.merge(to_join, on=\"hadm_id\", how=\"left\").rename(columns={\"icd_code\": str(i) + \"_icd\"})\n",
    "        df = df.merge(desc_icd, how=\"left\", left_on=(str(i) + \"_icd\"), right_on=\"icd_code\")\n",
    "        df = df.rename(columns={\"long_title\":str(i) + \"_desc_icd\"})\n",
    "        df = df.drop(\"icd_code\", axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohort Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM mimic_hosp.diagnoses_icd')\n",
    "icds = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "icds = pd.DataFrame(icds, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 1500)\n",
    "pd.set_option(\"display.max_columns\", 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#consider all icd codes regarding heart failure\n",
    "hf = icds.loc[icds[\"icd_code\"].str.contains(\"42821\") | (icds[\"icd_code\"].str.contains(\"42823\")) | (icds[\"icd_code\"].str.contains(\"42831\")) |\n",
    "        (icds[\"icd_code\"].str.contains(\"42833\")) | (icds[\"icd_code\"].str.contains(\"42841\"))| (icds[\"icd_code\"].str.contains(\"42843\"))\n",
    "        | (icds[\"icd_code\"].str.contains(\"I5021\")) |  (icds[\"icd_code\"].str.contains(\"I5023\")) |(icds[\"icd_code\"].str.contains(\"I5031\"))|\n",
    "        (icds[\"icd_code\"].str.contains(\"I5033\")) |\n",
    "        (icds[\"icd_code\"].str.contains(\"I5041\"))|\n",
    "        (icds[\"icd_code\"].str.contains(\"I5042\"))|\n",
    "        (icds[\"icd_code\"].str.contains(\"I5043\"))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.reset_index()\n",
    "hf = hf.drop(\"index\", axis=1)\n",
    "hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * FROM mimic_hosp.d_icd_diagnoses\")\n",
    "desc_icd = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "desc_icd = pd.DataFrame(desc_icd, columns=cols)\n",
    "desc_icd = desc_icd[[\"icd_code\", \"long_title\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = hf.merge(desc_icd, on=\"icd_code\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(\"SELECT * from mimic_hosp.drgcodes\")\n",
    "drgs = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "drgs = pd.DataFrame(drgs, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_drg = drgs.loc[drgs[\"hadm_id\"].isin(list(hf[\"hadm_id\"]))]\n",
    "hf_drg = hf_drg.loc[hf_drg[\"drg_type\"] == \"APR\"].drop_duplicates([\"subject_id\", \"hadm_id\", \"description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list([\"Heart Failure\", \"Cardiac Catheterization w/ Circ Disord Exc Ischemic Heart Disease\",\"Percutaneous Cardiovascular Procedures w/o AMI\",\n",
    "\"Cardiac Arrhythmia & Conduction Disorders\",\n",
    "\"Acute Myocardial Infarction\",\n",
    "\"Percutaneous Cardiovascular Procedures w/ AMI\",\n",
    "\"Cardiac Catheterization for Ischemic Heart Disease\",\n",
    "\"Cardiac Defibrillator & Heart Assist Anomaly\",\n",
    "\"Cardiac Valve Procedures w/ Cardiac Catheterization\",\n",
    "\"Coronary Bypass w/ Cardiac Cath Or Percutaneous Cardiac Procedure\",\n",
    "\"Other Circulatory System Diagnoses\"\n",
    "         ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_filter = hf_drg.loc[hf_drg[\"description\"].isin(l)]\n",
    "hf_filter = hf_filter.sort_values([\"hadm_id\", \"drg_code\"])\n",
    "hf_filter = hf_filter.drop_duplicates(\"hadm_id\", keep=\"first\")\n",
    "hf_filter = hf_filter.reset_index()\n",
    "hf_filter.drop(\"index\", axis=1,inplace=True)\n",
    "hadms = list(hf_filter[\"hadm_id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data fetching for the cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM mimic_hosp.diagnoses_icd where hadm_id = any(%s)', [hadms])\n",
    "icds = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "icds = pd.DataFrame(icds, columns=cols)\n",
    "hf_diag = get_diagnoses(hf_filter, hadms, 3)\n",
    "hf_adm = get_adms(hf_diag, hadms)\n",
    "hf_adm = hf_adm.reset_index()\n",
    "hf_adm.drop(\"index\", axis=1, inplace=True)\n",
    "hf_t = get_transfers(hf_adm, hadms)\n",
    "hf_p = get_patients(hf_t)\n",
    "hf_s = get_services(hf_p, hadms)\n",
    "hf_proc = get_procedures(hf_s, hadms)\n",
    "hf_med = get_med_count(hf_proc,hf_t, hadms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Laboratory Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM mimic_hosp.d_labitems')\n",
    "lab_d = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "lab_d = pd.DataFrame(lab_d, columns=cols)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute('SELECT * FROM mimic_hosp.labevents where hadm_id = any(%s)', [hadms])\n",
    "labs = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "labs = pd.DataFrame(labs, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_w_detail = labs.merge(lab_d, on=\"itemid\", how=\"inner\")\n",
    "lab_w_detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_med[\"LOS\"] = hf_med[\"dischtime\"] - hf_med[\"admittime\"]\n",
    "hf_med[\"transfer_duration\"] = hf_med[\"outtime\"] - hf_med[\"intime\"]\n",
    "lab_w_detail.groupby([\"itemid\", \"label\"]).count().sort_values(\"subject_id\", ascending=False)\n",
    "lab_w_detail = lab_w_detail.sort_values([\"hadm_id\", \"charttime\"])\n",
    "lab_w_detail = lab_w_detail.loc[lab_w_detail[\"hadm_id\"].isin(hadms)]\n",
    "hf_t = hf_t.loc[hf_t[\"1_desc_icd\"].str.contains(\"heart failure\", na=False)]\n",
    "hf_t = hf_t.reset_index()\n",
    "hadms = list(hf_t[\"hadm_id\"].unique())\n",
    "hadms = list(map(int, hadms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlcode = '''\n",
    "select *\n",
    "from lab_w_detail\n",
    "left join hf_t on lab_w_detail.hadm_id=hf_t.hadm_id\n",
    "where lab_w_detail.charttime >= hf_t.intime and lab_w_detail.charttime <= hf_t.outtime\n",
    "'''\n",
    "\n",
    "newdf = ps.sqldf(sqlcode,locals())\n",
    "newdf = newdf.loc[:,~newdf.columns.duplicated()]\n",
    "med_count = newdf.groupby([\"hadm_id\",\"transfer_id\"]).count()\n",
    "med_count = med_count.reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = med_count.drop(['subject_id', 'specimen_id','itemid', 'charttime', 'storetime', 'value', 'valuenum', 'valueuom',\n",
    "       'ref_range_lower', 'ref_range_upper', 'flag', 'priority', 'comments',\n",
    "       'label', 'fluid', 'category', 'loinc_code', 'eventtype', 'careunit',\n",
    "       'intime', 'outtime', 'drg_type', 'drg_code', 'description',\n",
    "       'drg_severity', 'drg_mortality', 'count_icd', '1_icd', '1_desc_icd',\n",
    "       '2_icd', '2_desc_icd', '3_icd', '3_desc_icd',\n",
    "       'admittime', 'dischtime', 'deathtime', 'admission_type',\n",
    "       'admission_location', 'discharge_location', 'insurance', 'language',\n",
    "       'marital_status', 'ethnicity', 'edregtime', 'edouttime',\n",
    "       'hospital_expire_flag'], axis=1)\n",
    "x = x.rename(columns={\"labevent_id\":\"lab_count\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hf_med.merge(x, on=[\"hadm_id\", \"transfer_id\"], how=\"left\")\n",
    "df = df.drop_duplicates([\"hadm_id\", \"transfer_id\", \"lab_count\"])\n",
    "df = df.rename({\"case:concept:name\":\"hadm_id\"}, axis=1)\n",
    "df = df.rename({\"careunit\":\"concept:name\"}, axis=1)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['drg_type', 'drg_code', 'description', 'drg_severity',\n",
    "       'drg_mortality','1_icd', '1_desc_icd', '2_icd',\n",
    "       '2_desc_icd', '3_icd', '3_desc_icd', 'language','edregtime', 'edouttime','hospital_expire_flag','admission_age_group', 'service', 'service_time', 'proc_icd_code',\n",
    "       'proc_seq_num', 'proc_icd_version', 'proc_long_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['anchor_age',\n",
    "       'anchor_year', 'anchor_year_group', 'dod', 'transfer_year','dod'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.DataFrame(data=None, columns=df.columns)\n",
    "d = {'subject_id':'first', 'hadm_id':'first', 'transfer_id':'first', 'eventtype':'first', \n",
    "     'anchor_real_year':'first', 'transfer_real_year':'first', 'admission_age':'first', 'med_count':'sum',\n",
    "       'LOS':'first', 'transfer_duration':'sum', 'lab_count':'sum',    \n",
    "     'intime':'min', 'outtime':'max', 'count_icd':'first',\n",
    "    'admittime':'first', 'dischtime':'first', 'deathtime':'first', 'admission_type':'first', 'admission_location':'first', 'discharge_location':'first',\n",
    "       'insurance':'first', 'marital_status':'first', 'ethnicity':'first', 'gender':'first', 'transfer_age':'first'}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"transfer_duration\"] = pd.to_timedelta(df[\"transfer_duration\"])\n",
    "arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(df[\"hadm_id\"].unique()):\n",
    "    print(i)\n",
    "    hadm = df.loc[df[\"hadm_id\"] == i]\n",
    "    consecutive_array = (hadm[\"concept:name\"] != hadm[\"concept:name\"].shift()).cumsum().values\n",
    "    new_hadm = hadm.groupby([consecutive_array, 'concept:name']).agg(d).reset_index(level=1)\n",
    "    arr.append(new_hadm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf = pd.concat(arr, axis=0)\n",
    "newdf = newdf.drop([\"anchor_real_year\", \"transfer_real_year\", \"admission_age\"], axis=1)\n",
    "newdf = newdf.reset_index().drop(\"index\", axis=1)\n",
    "newdf[\"LOS\"] = pd.to_timedelta(newdf[\"LOS\"])\n",
    "newdf[\"hadm_id\"] = newdf[\"hadm_id\"].astype(\"object\")\n",
    "hadms = list(newdf[\"hadm_id\"].unique())\n",
    "\n",
    "#retrieve lab values for the modified list of patients\n",
    "cursor.execute('SELECT * FROM mimic_hosp.d_labitems')\n",
    "lab_d = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "lab_d = pd.DataFrame(lab_d, columns=cols)   \n",
    "\n",
    "cursor.execute('SELECT * FROM mimic_hosp.labevents where hadm_id = any(%s)', [hadms])\n",
    "hf_lab = cursor.fetchall()\n",
    "cols = list(map(lambda x: x[0], cursor.description))\n",
    "hf_lab = pd.DataFrame(hf_lab, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf_lab = hf_lab.merge(lab_d, on=\"itemid\", how=\"inner\")\n",
    "labs_rnn = [\"Creatinine\", \"Urea Nitrogen\", \"Hemoglobin\", \"Glucose\", \"Red Blood Cells\"]\n",
    "hf_lab_new = hf_lab.loc[hf_lab[\"label\"].isin(labs_rnn)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map lab event to department\n",
    "sqlcode = '''\n",
    "select *\n",
    "from hf_lab_new\n",
    "inner join newdf on hf_lab_new.hadm_id=newdf.hadm_id\n",
    "where hf_lab_new.charttime >= newdf.intime and hf_lab_new.charttime <= newdf.outtime \n",
    "\n",
    "'''\n",
    "\n",
    "newdf_labs = ps.sqldf(sqlcode,locals())\n",
    "newdf_labs = newdf_labs.loc[:,~newdf_labs.columns.duplicated()]\n",
    "newdf_labs = newdf_labs.sort_values([\"subject_id\", \"hadm_id\", \"charttime\"])\n",
    "newdf_labs = newdf_labs.reset_index()\n",
    "newdf_labs = newdf_labs.drop(\"index\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_info = newdf_labs.groupby([\"subject_id\", \"hadm_id\"]).last().reset_index()[[\"subject_id\", \"hadm_id\", \"charttime\"]]\n",
    "newdf_labs_2 = newdf_labs\n",
    "times = list(discharge_info[\"charttime\"])\n",
    "newdf_labs_2 = newdf_labs_2.loc[newdf_labs_2[\"charttime\"].isin(times)]\n",
    "newdf_labs_back = newdf_labs\n",
    "discharge_temp = []\n",
    "\n",
    "for index, row in discharge_info.iterrows():\n",
    "    print(index)\n",
    "    labs = newdf_labs_2.loc[(newdf_labs_2[\"hadm_id\"] == row[\"hadm_id\"]) & (newdf_labs_2[\"charttime\"] == row[\"charttime\"])]\n",
    "    labs[\"concept:name\"] = \"Discharged\"\n",
    "    discharge_temp.append(labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discharge_temp = pd.concat(discharge_temp, axis=0)\n",
    "labs_disch = pd.concat([newdf_labs_back,discharge_temp])\n",
    "lab_df = labs_disch.groupby([\"subject_id\",\"hadm_id\", \"concept:name\", \"label\", \"intime\", \"outtime\"]).agg({\"valuenum\":\"mean\"}).reset_index()\n",
    "newdf.loc[newdf[\"eventtype\"] == \"discharge\", \"concept:name\"] = \"Discharged\"\n",
    "hadm_w_discharge = list(newdf.loc[newdf[\"concept:name\"] == \"Discharged\"][\"hadm_id\"].unique())\n",
    "lab_df = lab_df.loc[lab_df[\"hadm_id\"].isin(hadm_w_discharge)]\n",
    "newdf = newdf.loc[newdf[\"hadm_id\"].isin(hadm_w_discharge)]\n",
    "\n",
    "lab_df = lab_df.reset_index()\n",
    "lab_df.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "lab_df = lab_df.reset_index()\n",
    "lab_df.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "newdf = newdf.reset_index()\n",
    "newdf.drop(\"index\", axis=1, inplace=True)\n",
    "\n",
    "newdf[\"intime\"] = newdf[\"intime\"].apply(lambda x: pd.to_datetime(x))\n",
    "newdf[\"outtime\"] = newdf[\"outtime\"].apply(lambda x: pd.to_datetime(x))\n",
    "newdf.loc[newdf[\"outtime\"].isna(), \"outtime\"] = newdf[\"intime\"] + pd.Timedelta(seconds=1)\n",
    "newdf[\"transfer_duration\"] = newdf[\"outtime\"] - newdf[\"intime\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#lab values of Discharged do not have the correct timestamp yet and cannot be merged!\n",
    "deps = newdf.loc[newdf[\"concept:name\"] == \"Discharged\"][[\"subject_id\", \"hadm_id\", \"intime\", \"outtime\", \"concept:name\"]]\n",
    "y = lab_df.loc[lab_df[\"concept:name\"] == \"Discharged\"]\n",
    "for index, row in y.iterrows():\n",
    "    print(index)\n",
    "    time = deps.loc[deps[\"hadm_id\"] == row[\"hadm_id\"]]\n",
    "    time = time.reset_index()\n",
    "    lab_df.loc[index, \"intime\"] = time[\"intime\"][0]\n",
    "    lab_df.loc[index, \"outtime\"] = time[\"outtime\"][0]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_df[\"intime\"] = lab_df[\"intime\"].apply(lambda x: pd.to_datetime(x))\n",
    "lab_df[\"outtime\"] = lab_df[\"outtime\"].apply(lambda x: pd.to_datetime(x))\n",
    "lab_df = lab_df[[\"subject_id\", \"hadm_id\", \"intime\", \"outtime\", \"concept:name\", \"valuenum\", \"label\"]]\n",
    "\n",
    "lab_pm = newdf\n",
    "for label in labs_rnn:\n",
    "    print(label)\n",
    "    df_single = lab_df.loc[lab_df[\"label\"] == label]\n",
    "    df_single.rename({\"valuenum\":label}, axis=1, inplace=True)\n",
    "    df_single.drop(\"label\", axis=1, inplace=True)\n",
    "    df_single = df_single[[\"subject_id\", \"hadm_id\", \"intime\", \"outtime\", \"concept:name\", label]]\n",
    "    lab_pm = lab_pm.merge(df_single, on=[\"subject_id\", \"hadm_id\", \"intime\", \"outtime\", \"concept:name\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_pm = lab_pm.loc[~lab_pm[\"transfer_id\"].isna()]\n",
    "disch_fac = [\"SKILLED NURSING FACILITY\", \"HOME\", \"HOME HEALTH CARE\"]\n",
    "filtered_pm = lab_pm.loc[lab_pm[\"discharge_location\"].isin(disch_fac)]\n",
    "filtered_pm = filtered_pm.reset_index().drop(\"index\", axis=1)\n",
    "filtered_pm = filtered_pm.drop(\"deathtime\", axis=1)\n",
    "filtered_pm = filtered_pm.drop(['transfer_id', 'eventtype'], axis=1)\n",
    "filtered_pm.to_csv(\"../data/AI_HEART_FAILURE_CNN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
